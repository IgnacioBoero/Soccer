{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open .pkl data\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = 'data/trajectories.pkl'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get diferent types of events\n",
    "evnt_types = set()\n",
    "for traj in data:\n",
    "    for event in traj[:]:\n",
    "        evnt_types.add(event['action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                         Field & action constants                            #\n",
    "# --------------------------------------------------------------------------- #\n",
    "FIELD_X: int = 104  # metres (length)\n",
    "FIELD_Y: int = 68   # metres (width)\n",
    "\n",
    "ACTION_ID = {\n",
    "    \"pass\": 0, \"cross\": 0,\n",
    "    \"dribble\": 1, \"take_on\": 1,\n",
    "    \"shot\": 2,\n",
    "}\n",
    "\n",
    "N_ACTIONS: int = 3  # one‑hot length\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                      Core encoding helpers                                  #\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "def encode_action(evt: Dict[str, Any]) -> np.ndarray:\n",
    "    \"\"\"Return 7‑D float32 vector: [one‑hot(3), x_s, y_s, x_e, y_e].\"\"\"\n",
    "    one_hot = np.zeros(N_ACTIONS, dtype=np.float32)\n",
    "    aid = ACTION_ID.get(evt[\"action\"], None)\n",
    "    if aid is None:\n",
    "        raise ValueError(f\"Unknown action: {evt['action']}\")\n",
    "    one_hot[aid] = 1.0\n",
    "\n",
    "    start = np.array(evt[\"ball_start\"], dtype=np.float32)\n",
    "    end   = np.array(evt.get(\"ball_end\", evt[\"ball_start\"]), dtype=np.float32)\n",
    "    return np.concatenate([one_hot, start, end])  # shape (7,)\n",
    "\n",
    "\n",
    "def build_state(evt: Dict[str, Any]) -> np.ndarray:\n",
    "    \"\"\"Return 4×104×68 float32 tensor (channels first).\"\"\"\n",
    "    # 1) Sparse occupancy maps ------------------------------------------- #\n",
    "    tm = np.zeros((FIELD_X, FIELD_Y), dtype=np.float32)  # teammates\n",
    "    op = np.zeros((FIELD_X, FIELD_Y), dtype=np.float32)  # opponents\n",
    "\n",
    "    for pl in evt[\"player_loc\"].values[0]:\n",
    "        x, y = pl[\"location\"]\n",
    "        xi = int(round(np.clip(x, 0, FIELD_X - 1)))\n",
    "        yi = int(round(np.clip(y, 0, FIELD_Y - 1)))\n",
    "        if pl[\"teammate\"]:\n",
    "            tm[xi, yi] = 1.0\n",
    "        else:\n",
    "            op[xi, yi] = 1.0\n",
    "\n",
    "    # 2) Distance & angle maps ------------------------------------------- #\n",
    "    bx, by = evt[\"ball_start\"]\n",
    "    xs = np.arange(FIELD_X).reshape(-1, 1)  # (104,1)\n",
    "    ys = np.arange(FIELD_Y).reshape(1, -1)  # (1,68)\n",
    "\n",
    "    dx = xs - bx  # broadcasting\n",
    "    dy = ys - by\n",
    "\n",
    "    dist  = np.sqrt(dx * dx + dy * dy, dtype=np.float32)\n",
    "    angle = np.arctan2(dy, dx, dtype=np.float32) / math.pi  # normalise → [‑1,1]\n",
    "\n",
    "    state = np.stack([tm, op, dist, angle], axis=0)  # (4,104,68)\n",
    "    return state.astype(np.float32)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                   Reward & return computation                               #\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "def reward_fn(evt: Dict[str, Any]) -> float:\n",
    "    \"\"\"Sparse proxy: +1 if a *shot* succeeds, else 0.\"\"\"\n",
    "    return 1.0 if evt[\"action\"] == \"shot\" and evt.get(\"outcome\", False) else 0.0\n",
    "\n",
    "\n",
    "def discount_cumsum(rewards: List[float], gamma: float) -> List[float]:\n",
    "    G, out = 0.0, [0.0] * len(rewards)\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        G = rewards[t] + gamma * G\n",
    "        out[t] = G\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                        Processing pipeline                                  #\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "def process_trajectories(data: List[List[Dict[str, Any]]],\n",
    "                         gamma: float = 0.99) -> List[List[Dict[str, Any]]]:\n",
    "    \"\"\"Convert raw JSON trajectories → training‑ready format.\"\"\"\n",
    "    processed: List[List[Dict[str, Any]]] = []\n",
    "\n",
    "    for traj_id, traj in enumerate(data):\n",
    "        steps: List[Dict[str, Any]] = []\n",
    "        # encode states & actions first (next_* placeholders) ------------- #\n",
    "        for t, evt in enumerate(traj):\n",
    "            step = {\n",
    "                \"state\": torch.tensor(build_state(evt)),\n",
    "                \"action\": torch.tensor(encode_action(evt)),\n",
    "                \"reward\": 0.0,  # placeholder, filled later\n",
    "                \"next_state\": None,\n",
    "                \"next_action\": None,\n",
    "                \"done\": False,\n",
    "                \"traj_id\": traj_id,\n",
    "                \"t\": t,\n",
    "            }\n",
    "            steps.append(step)\n",
    "\n",
    "        # pointer to next state/action & terminal flag -------------------- #\n",
    "        for i in range(len(steps) - 1):\n",
    "            steps[i][\"next_state\"] = steps[i + 1][\"state\"]\n",
    "            steps[i][\"next_action\"] = steps[i + 1][\"action\"]\n",
    "        steps[-1][\"done\"] = True\n",
    "\n",
    "        # assign sparse reward only to terminal step ---------------------- #\n",
    "        steps[-1][\"reward\"] = reward_fn(traj[-1])\n",
    "        \n",
    "        # Monte‑Carlo returns (λ‑returns added later in training script) --- #\n",
    "        rewards = [s[\"reward\"] for s in steps]\n",
    "        Gs = discount_cumsum(rewards, gamma)\n",
    "        for s, G in zip(steps, Gs):\n",
    "            s[\"G\"] = G\n",
    "\n",
    "        processed.append(steps)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_state(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def plot_soccer_state(state: np.ndarray,\n",
    "                      teammate_thresh: float = 0.5,\n",
    "                      opponent_thresh: float = 0.5):\n",
    "    \"\"\"\n",
    "    Visualise a 4×104×68 state tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    state : np.ndarray\n",
    "        Tensor with channels:\n",
    "          0 – teammate occupancy   (binary/sparse)\n",
    "          1 – opponent occupancy   (binary/sparse)\n",
    "          2 – distance-to-ball map (float, 0 at ball)\n",
    "          3 – angle-to-ball map    (unused here)\n",
    "    teammate_thresh, opponent_thresh : float\n",
    "        Value above which a grid-cell is considered occupied.\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 1. Unpack channels & locate entities\n",
    "    teammates = state[0] > teammate_thresh\n",
    "    opponents = state[1] > opponent_thresh\n",
    "\n",
    "    # player coordinates (x = length, y = width)\n",
    "    tx, ty = np.where(teammates)\n",
    "    ox, oy = np.where(opponents)\n",
    "\n",
    "    # ball = pixel of minimum distance\n",
    "    bx, by = np.unravel_index(state[2].argmin(), state[2].shape)\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 2. Draw the pitch\n",
    "    L, W = 104, 68                       # metres\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.add_patch(Rectangle((0, 0), L, W, fill=False, lw=2, color=\"black\"))\n",
    "    ax.plot([L / 2, L / 2], [0, W], color=\"black\")       # half-way line\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # 3. Scatter entities\n",
    "    ax.scatter(tx, ty, c=\"blue\",  s=40, label=\"Teammate\")\n",
    "    ax.scatter(ox, oy, c=\"red\",   s=40, label=\"Opponent\")\n",
    "    ax.scatter(bx, by, c=\"orange\", s=120, edgecolors=\"black\",\n",
    "               marker=\"o\", label=\"Ball\")\n",
    "\n",
    "    # Aesthetics -------------------------------------------------------- #\n",
    "    ax.set_xlim(0, L)\n",
    "    ax.set_ylim(0, W)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.invert_yaxis()                    # origin top-left like tracking data\n",
    "    ax.set_xlabel(\"Metres (length)\")\n",
    "    ax.set_ylabel(\"Metres (width)\")\n",
    "    ax.set_title(\"Soccer state snapshot\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_soccer_state(build_state(data[0][6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meam6000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
